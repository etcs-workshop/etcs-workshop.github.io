# Workshop on Emerging Themes in Computational Statistics
__Dates: 19th (Wed) &mdash; 20th (Thu) February, 2020__  
__Location: The Institute of Statistical Mathematics, Tokyo, Japan__  
__Registration: No registration required (except for dinner)__

### Outline

Computational statistics is a rapidly developing research field due to the increasing
high demand in analysing large and complex data in many areas of science. Motivated
by the recent innovations in efficient computational techniques for statistical
inference and a variety of computationally challenging applications, this workshop aims
to facilitate discussions amongst researchers working on different aspects of statistical
computations, and promotes new ideas in both methodological and applied directions.

### Timetable (Tentative)

|                     |      Day 1 (19 Feb)     |   Day 2 (20 Feb)   |
|:-------------------:|:-----------------------:|:------------------:|
| 10:00 &ndash; 11:00 |       Chris Oates       |    Scott Sisson    |
| 11:00 &ndash; 11:30 |      _Coffee break_     |   _Coffee break_   |
| 11:30 &ndash; 12:30 |  Francois-Xavier Briol  |   Richard Gerlach  |
| 12:30 &ndash; 14:00 |         _Lunch_         |       _Lunch_      |
| 14:00 &ndash; 15:00 |    Heishiro Kanagawa    |  Pavel Shevchenko  |
| 15:00 &ndash; 15:30 |     _Afternoon tea_     |   _Afternoon tea_  |
| 15:30 &ndash; 16:15 |     Shin-Itiro Goto     |   Takeru Matsuda   |
| 16:15 &ndash; 17:00 |        Wenkai Xu        |  Daisuke Murakami  |
|  17:00 &ndash; late |    _Workshop dinner_    |                    |

### Speakers

* __Chris Oates (Newcastle University, Alan Turing Institute, UK)__  
  __Title:__ Gaussian Process Approximation of Deterministic Functions  
  __Abstract:__ Despite the ubiquity of Gaussian process regression in the applied context, almost no theoretical results are available that account for the fact that parameters of the covariance kernel need to be jointly estimated from the dataset. The lack of theoretical understanding draws into question whether Gaussian process regression should be used at all in important, e.g. safety-critical, applications. To gain some insight, we studied the scenario where the scale parameter of the kernel is estimated using maximum likelihood. Our main result is a bound on the rate at which the Gaussian process can become overconfident as the size of the dataset is increased. The analysis is based on a combination of techniques from nonparametric regression and scattered data interpolation, and is joint work with Toni Karvonen, George Wynne, Filip Tronarp and Simo Särkkä.  

* __Francois-Xavier Briol (University College London, Alan Turing Institute, UK)__  
  __Title:__ Statistical Inference for Generative Models with Maximum Mean Discrepancy  
  __Abstract:__ While likelihood-based inference and its variants provide a statistically efficient and widely applicable approach to parametric inference, their application to models involving intractable likelihoods poses challenges. In this work, we study a class of minimum distance estimators for intractable generative models, that is, statistical models for which the likelihood is intractable, but simulation is cheap. The distance considered, maximum mean discrepancy (MMD) is defined through the embedding of probability measures into a reproducing kernel Hilbert space (RKHS). We study the theoretical properties of these estimators, showing that they are consistent and asymptotically normal. A main advantage of these estimators is the flexibility offered by the choice of kernel, which can be used to trade-off statistical efficiency and robustness. Studying the geometry induced by MMD on the parameter space, we introduce a novel natural gradient descent-like algorithm for efficient implementation of these estimators. We illustrate the relevance of our theoretical results on several classes of models including a discrete-time latent Markov process and a multivariate stochastic differential equation model.  

* __Heishiro Kanagawa (University College London, UK)__  
  __Title:__  
  __Abstract:__  

* __Shin-Itiro Goto (Institute of Statistical Mathematics, Japan)__  
  __Title:__  
  __Abstract:__  

* __Wenkai Xu (University College London, UK)__  
  __Title:__ A Stein Goodness-of-fit Test for Directional Distributions  
  __Abstract:__ In many fields, data appears in the form of direction (unit vector) and usual statistical procedures are not applicable to such directional data. In this study, we propose non-parametric goodness-of-fit testing procedures for general directional distributions based on kernel Stein discrepancy. Our method is based on Stein's operator on spheres, which is derived by using Stokes' theorem. Notably, the proposed method is applicable to distributions with an intractable normalization constant, which commonly appear in directional statistics. Experimental results demonstrate that the proposed methods control type-I error well and have larger power than existing tests, including the test based on the maximum mean discrepancy.  

* __Scott Sisson (University of New South Wales, Australia)__  
  __Title:__  
  __Abstract:__  

* __Richard Gerlach (University of Sydney, Australia)__  
  __Title:__  
  __Abstract:__  

* __Pavel Shevchenko (Macquarie University, Australia)__  
  __Title:__  
  __Abstract:__  

* __Takeru Matsuda (University of Tokyo, Japan)__  
  __Title:__ Information Criteria for Non-Normalized Models  
  __Abstract:__ Many statistical models are given in the form of non-normalized densities with an intractable normalization constant. Since maximum likelihood estimation is computationally intensive for these models, several estimation methods have been developed which do not require explicit computation of the normalization constant, such as noise contrastive estimation (NCE) and score matching. However, model selection methods for general non-normalized models have not been proposed so far. In this study, we develop information criteria for non-normalized models estimated by NCE or score matching. They are derived as approximately unbiased estimators of discrepancy measures for non-normalized models. Experimental results demonstrate that the proposed criteria enable selection of the appro- priate non-normalized model in a data-driven manner. Extension to a finite mixture of non-normalized models is also discussed.  

* __Daisuke Murakami (Institute of Statistical Mathematics, Japan)__  
  __Title:__  A Scalable Spatial Additive Modeling for Large Dataset  
  __Abstract:__  Regression problem for large samples is now commonplace, and fast and memory-efficient egression models accommodating group effects, non-linear effects, and other effects are increasingly important. This study develops a spatial additive regression approach for large samples. Therein, we developed an algorithm estimating spatial and non-spatial effects whose computational complexity and memory consumption are independent of the sample size after pre-conditioning. The performance of the developed approach is examined through Monte Carlo simulation experiments and empirical application.  

### Lunch

Popular lunch adventures around ISM:
* Tachikawa City Hall (立川市役所)
* Bento boxes at Polar Science Museum (南極・北極科学館)
* Zuikyo Chinese Restaurant (中国料理・瑞京)
* Lalaport Tachikawa (ららぽーと立川立飛店)
* Tokyo District Court Tachikawa Branch (東京地方裁判所)
* Local Autonomy College (自治大学校)

### Dinner

TBA

### Accommodation

* [Palace Hotel Tachikawa](https://www.palace-t.co.jp/english/)
* [Tachikawa Grand Hotel](https://www.guestreservations.com/tachikawa-grand-hotel/booking)
* [Hotel Nikko Tachikawa](https://www.okura-nikko.com/japan/tokyo/hotel-nikko-tachikawa-tokyo/)

### Organisation

* Wilson Chen, wilson(at-symbol)ism.ac.jp
* Yi Jiang, jiangyi(at-symbol)ism.ac.jp
* Tomoko Matsui, tmatsui(at-symbol)ism.ac.jp
